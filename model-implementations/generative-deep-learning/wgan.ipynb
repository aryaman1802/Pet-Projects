{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wasserstein Generative Adversarial Network (WGAN)\n",
    "\n",
    "Paper: [Wasserstein GAN](https://arxiv.org/pdf/1701.07875)\n",
    "\n",
    "Helpful Resources:\n",
    "- [Aladdin Persson's playlist on GANs](https://youtube.com/playlist?list=PLhhyoLH6IjfwIp8bZnzX8QR30TRcHO8Va&si=8ooImkbbXhCUC1xB)\n",
    "- [GANs specialization on Coursera](https://www.coursera.org/specializations/generative-adversarial-networks-gans)\n",
    "- [Stanford's Deep Generative Models playlist](https://youtube.com/playlist?list=PLoROMvodv4rPOWA-omMM6STXaWW4FvJT8&si=N_TpTe1bPIhte-t8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook just includes the implementation of the WGAN model and its training loop. The results are not shown here.\n",
    "\n",
    "Feel free to check the results on my Kaggle notebook: https://www.kaggle.com/code/aryamanbansal/wgan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports and some helpful utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports done!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import make_grid\n",
    "from torchinfo import summary\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import gc\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Imports done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utility functions created!\n"
     ]
    }
   ],
   "source": [
    "def get_torch_version():\n",
    "    \"\"\"\n",
    "    Returns the version of PyTorch installed.\n",
    "    \"\"\"\n",
    "    torch_version = torch.__version__.split(\"+\")[0]\n",
    "    torch_number = torch_version.split(\".\")[:2]\n",
    "    torch_number_float = torch_number[0] + \".\" + torch_number[1]\n",
    "    torch_number_float = float(torch_number_float)\n",
    "    return torch_number_float\n",
    "\n",
    "\n",
    "def set_seed(seed: int = 42):\n",
    "    \"\"\"\n",
    "    Seeds basic parameters for reproducibility of results\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        if get_torch_version() <= 1.7:\n",
    "            torch.set_deterministic(True)\n",
    "        else:\n",
    "            torch.use_deterministic_algorithms(True)\n",
    "\n",
    "\n",
    "def set_scheduler(scheduler, results, scheduler_on):\n",
    "    \"\"\"\n",
    "    Makes the neccessary updates to the scheduler.\n",
    "    \n",
    "    Parameters:\n",
    "    - scheduler: torch.optim.lr_scheduler, the scheduler to update.\n",
    "    - results: dict, the results dictionary containing the training and test metric values.\n",
    "        Keys in the results dictionary are: \"gen_train_loss\", \"gen_val_loss\", \n",
    "                                            \"disc_train_loss\", \"disc_val_loss\".\n",
    "    - scheduler_on: str, the metric to use for the scheduler update.\n",
    "    \"\"\"\n",
    "    if scheduler_on == \"gen_val_loss\":\n",
    "        scheduler.step(results[\"gen_val_loss\"][-1])\n",
    "    if scheduler_on == \"disc_val_loss\":\n",
    "        scheduler.step(results[\"disc_val_loss\"][-1])\n",
    "    elif scheduler_on == \"gen_train_loss\":\n",
    "        scheduler.step(results[\"gen_train_loss\"][-1])\n",
    "    elif scheduler_on == \"disc_train_loss\":\n",
    "        scheduler.step(results[\"disc_train_loss\"][-1])\n",
    "    else:\n",
    "        raise ValueError(\"Invalid `scheduler_on` choice.\")\n",
    "    return scheduler\n",
    "\n",
    "\n",
    "def save_model_info(path: str, model, model_name, optimizer, optimizer_name, \n",
    "                    scheduler=None, scheduler_name=\"\"):\n",
    "    \"\"\"\n",
    "    Saves the model and optimizer weights to the specified path.\n",
    "\n",
    "    Parameters:\n",
    "    - path: str, the path to the directory to save the model and optimizer weights.\n",
    "    - model: nn.Module, the model to save.\n",
    "    - model_name: str, the name of the model weights file.\n",
    "    - optimizer: torch.optim, the optimizer to save.\n",
    "    - optimizer_name: str, the name of the optimizer weights file.\n",
    "    - scheduler: torch.optim.lr_scheduler, the scheduler to save.\n",
    "    - scheduler_name: str, the name of the scheduler weights file.\n",
    "\n",
    "    Free advice:\n",
    "    A good practice is to transfer the model to the CPU before calling torch.save as this \n",
    "    will save tensors as CPU tensors and not as CUDA tensors. This will help in loading\n",
    "    the model onto any machine, whether it contains CUDA capabilities or not.\n",
    "    \"\"\"\n",
    "    model.to(\"cpu\")\n",
    "    torch.save(model.state_dict(), os.path.join(path,model_name))\n",
    "    torch.save(optimizer.state_dict(), os.path.join(path,optimizer_name))\n",
    "    if scheduler is not None:\n",
    "        torch.save(scheduler.state_dict(), os.path.join(path,scheduler_name))    \n",
    "    print(\"Model info saved!\")\n",
    "    \n",
    "    \n",
    "def load_model_info(path, device, model, model_name, optimizer, optimizer_name, \n",
    "                    scheduler=None, scheduler_name=\"\"):\n",
    "    \"\"\"\n",
    "    Loads the model and optimizer weights from the specified path.\n",
    "\n",
    "    Parameters:\n",
    "    - path: str, the path to the directory containing the model and optimizer weights.\n",
    "    - device: str, the device to load the model and optimizer weights onto.\n",
    "    - model: nn.Module, the model to load the weights into.\n",
    "    - model_name: str, the name of the model weights file.\n",
    "    - optimizer: torch.optim, the optimizer to load the weights into.\n",
    "    - optimizer_name: str, the name of the optimizer weights file.\n",
    "    - scheduler: torch.optim.lr_scheduler, the scheduler to load the weights into.\n",
    "    - scheduler_name: str, the name of the scheduler weights file.\n",
    "    \"\"\"\n",
    "    model.load_state_dict(torch.load(os.path.join(path,model_name)))\n",
    "    model.to(device)\n",
    "    optimizer.load_state_dict(torch.load(os.path.join(path,optimizer_name)))\n",
    "    if scheduler is not None:\n",
    "        scheduler.load_state_dict(torch.load(os.path.join(path,scheduler_name)))\n",
    "    print(\"Model info loaded!\")\n",
    "    \n",
    "    \n",
    "def get_current_time():\n",
    "    \"\"\"Returns the current time in Toronto.\"\"\"\n",
    "    now = datetime.now(pytz.timezone('Canada/Eastern'))\n",
    "    current_time = now.strftime(\"%d_%m_%Y__%H_%M_%S\")\n",
    "    return current_time\n",
    "\n",
    "\n",
    "def show_tensor_images(image_tensor, num_images=25, size=(1,28,28)):\n",
    "    \"\"\"\n",
    "    Function for visualizing images: Given a tensor of images, \n",
    "    number of images, and size per image, plots and prints the \n",
    "    images in an uniform grid.\n",
    "    \"\"\"\n",
    "    image_tensor = (image_tensor + 1) / 2\n",
    "    image_unflat = image_tensor.detach().cpu()\n",
    "    image_grid = make_grid(image_unflat[:num_images], nrow=5)\n",
    "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualize_results(results):\n",
    "    \"\"\"\n",
    "    Plots the train and test losses of the generator and the discriminator.\n",
    "\n",
    "    results is dictionary with keys: \n",
    "        \"gen_train_loss\", \"gen_val_loss\", \"disc_train_loss\", \"disc_val_loss\".\n",
    "    \"\"\"\n",
    "    gen_train_loss = results[\"gen_train_loss\"]\n",
    "    gen_val_loss = results[\"gen_val_loss\"]\n",
    "    disc_train_loss = results[\"disc_train_loss\"]\n",
    "    disc_val_loss = results[\"disc_val_loss\"]\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12,4))\n",
    "    ax[0].set_xlabel(\"Epochs\")\n",
    "    ax[0].set_ylabel(\"Training Loss\")\n",
    "    ax[0].plot(gen_train_loss, label=\"generator\", color=\"orange\")\n",
    "    ax[0].plot(disc_train_loss, label=\"discriminator\", color=\"blue\")\n",
    "    ax[0].legend()\n",
    "    ax[1].set_xlabel(\"Epochs\")\n",
    "    ax[1].set_ylabel(\"Test Loss\")\n",
    "    ax[1].plot(gen_val_loss, label=\"generator\", color=\"orange\")\n",
    "    ax[1].plot(disc_val_loss, label=\"discriminator\", color=\"blue\")\n",
    "    ax[1].legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print(\"Utility functions created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some theory about WGANs\n",
    "\n",
    "Before we jump in to the code, let's understand the theory behind WGANs, and why we need them. \n",
    "\n",
    "Note: the following notes are heavily inspired by the [GANs specialization on Coursera](https://www.coursera.org/specializations/generative-adversarial-networks-gans).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Motivation**\n",
    "\n",
    "In simple GANs using binary cross entropy (BCE) loss, the generator tries to make the discriminator think its fake images are real. The issue arises because the generator's learning depends entirely on how the discriminator evaluates its images.\n",
    "\n",
    "When the discriminator strongly classifies an image as real (assigns higher probability to that image as real), the generator focuses heavily on producing that image repeatedly, leading to a lack of variety. Conversely, if the discriminator strongly classifies the image as fake, the generator receives almost no useful feedback, as BCE loss gives a vanishing gradient when predictions are very confident. This stalling of the generator’s learning leads to the bad scenario where the generator is stuck with no clear way to improve.\n",
    "\n",
    "This phenomenon occurs because BCE loss measures how well the discriminator classifies an image but doesn't give the generator useful signals when its outputs are far from realistic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Mode Collapse**\n",
    "\n",
    "- **What is it**: Mode collapse happens when the generator produces limited types of images (e.g., just one kind of dog) instead of a diverse set of realistic outputs.\n",
    "\n",
    "- **When does it happen**: Mode collapse occurs when the generator gets stuck generating one mode. The discriminator will eventually learn to differentiate the generator's fakes when this happens and outskill it, ending the model's learning. In other words, mode collapse often occurs when the generator \"overfits\" to fool the discriminator by creating only a few images that it knows will work well, ignoring the rest of the data distribution. It generally occurs when we use the BCE loss function to train GANs.\n",
    "\n",
    "- **Why does it happen**: This happens because the discriminator doesn't penalize the generator for repeatedly producing the same outputs, as long as they seem realistic. The generator's objective doesn’t explicitly encourage diversity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Problem with BCE Loss function**\n",
    "\n",
    "**TL;DR**: The BCE loss function is not a good choice for GANs because it can lead to vanishing gradient problem and mode collapse. In other words, the discriminator gets too good at distinguishing between real and fake values, and as a result, the generator doesn't get useful feedback to improve.\n",
    "\n",
    "> Binary Cross Entropy (BCE) loss function review. \n",
    "\n",
    "The BCE loss function is defined as:\n",
    "\n",
    "$$\\text{BCELoss} = -\\frac{1}{m} \\sum_{i=1}^m \\left[ y_i \\cdot \\text{log}(x_i) + (1 - y_i) \\cdot \\text{log}(1 - x_i) \\right]$$\n",
    "\n",
    "A simplified form of the above loss function is:\n",
    "\n",
    "$$\\text{BCELoss} \\quad = \\quad \\min\\limits_{d} \\max\\limits_{g} \\quad - \\left[ \\mathbb{E}(\\text{log}(d(x))) \\; + \\; \\mathbb{E}(1 - \\text{log}(d(g(z)))) \\right]$$\n",
    "\n",
    ", where:\n",
    "\n",
    "- $d$ is the discriminator\n",
    "- $g$ is the generator\n",
    "- $x$ is the real values\n",
    "- $z$ is the noise vector\n",
    "- $d(x)$ is the discriminator's prediction for real values\n",
    "- $g(z)$ is the fake values generated by the generator\n",
    "- $d(g(z))$ is the discriminator's prediction for fake values\n",
    "\n",
    "\n",
    "The first term ($y_i \\cdot \\text{log}(x_i)$) is for real values, and the second term ($(1 - y_i) \\cdot \\text{log}(1 - x_i)$) is for fake values.\n",
    "\n",
    "The discriminator's goal is to minimize the BCE loss function, because that means it's classifying things correctly. So its loss function is:\n",
    "\n",
    "$$\\text{min} \\left[ \\; y_i \\cdot \\text{log}(x_i) \\; + \\; (1 - y_i) \\cdot \\text{log}(1 - x_i) \\; \\right]$$\n",
    "\n",
    "OR\n",
    "\n",
    "$$\\min\\limits_{d} \\quad - \\left[ \\mathbb{E}(\\text{log}(d(x))) \\; + \\; \\mathbb{E}(1 - \\text{log}(d(g(z)))) \\right]$$\n",
    "\n",
    "\n",
    "While, the generator's goal is to maximize the BCE loss function, because that means the discriminator is doing poorly and is classifying it's fake values into reals. The generator only has control over the fake values, so its loss function is:\n",
    "\n",
    "$$\\text{max} \\left[ \\; (1 - y_i) \\cdot \\text{log}(1 - x_i) \\; \\right]$$\n",
    "\n",
    "OR\n",
    "\n",
    "$$\\max\\limits_{g} \\quad - \\left[ \\mathbb{E}(1 - \\text{log}(d(g(z)))) \\right]$$\n",
    "\n",
    "> The big picture of this minimax game.\n",
    "\n",
    "This maximization and minimization is often called a minimax game, at the end of which the goal of the entire GAN architecure is bring the generated data distribution and the real data distribution as close as possible. In other words, during the entire training process, the discriminator is trying to precisely classify which values are fake, and which are real, while the generator is trying to generate fake values that are as close to real as possible.\n",
    "\n",
    "> Roles of the generator and discriminator.\n",
    "\n",
    "However, let's take a step back again to the roles of the generator and discriminator. The discriminator needs to output just a single value prediction within zero and one, ie, whether the value it sees is fake or real. Whereas the generator actually needs to produce the realistic-looking fake value, which is a pretty complex output composed of multiple features to try and fool the discriminator, for example, an image. As a result, the discriminator's job tends to be a little bit easier. In other words, it's much easier to look at images in a museum than to actually paint those masterpieces. So, during training, it's quite common for the discriminator to outperform the generator, ie, the discriminator quickly learns to differentiate between real and fake values, and the generator can't keep up. This is where the problem arises.\n",
    "\n",
    "> Rise of the (vanishing gradient) problem with the BCE loss function.\n",
    "\n",
    "The fact that the discriminator quickly learns to outperform the generator isn't such a big problem at the beginning of training, because the discriminator isn't that good. So, initially, the discriminator is able to give useful feedback to the generator in the form of a non-zero gradient. However, as it gets better at training, it ability to distinguish between real and fake values becomes much more precise. As a result, as the discriminator keeps getting better, it starts giving less informative feedback to the generator. In fact, the discriminator might give gradients closer to zero, and that becomes unhelpful for the generator because then the generator doesn't know how to improve. This is how the vanishing gradient problem will arise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Earth Mover's Distance (EMD)**\n",
    "\n",
    "<!-- - EMD is one of the loss functions for GANs. -->\n",
    "- EMD is a concept and not a loss function.\n",
    "- It measures how different the generated data distribution and the real data distribution are. \n",
    "- It does so by estimating the amount of effort it takes to make the generated distribution equal to the real.\n",
    "- Intuitively, if the generate distribution was a pile of dirt, EMD measures how difficult it would be to move that pile of dirt and mold it into the shape and location of the real distribution.\n",
    "- EMD depends on both the distance and the amount that the generated distribution needs to be moved.\n",
    "- Unlike the BCE loss function, there gradient values are not confined between 0 and 1, ie, in EMD, gradients can be any value (from $-\\infty$ to $\\infty$), which is mitigates the vanishing gradient problem.  \n",
    "- GANs trained using EMD generally outperform the ones trained using the BCE loss function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Wasserstein Loss**\n",
    "\n",
    "> Introduction to the Wasserstein loss.\n",
    "\n",
    "The Wasserstein loss (aka W-loss) is an alternative loss function choice that approximates the Earth Mover's distance as follows:\n",
    "\n",
    "$$\\text{W-Loss} \\;\\;  = \\;\\; \\min\\limits_{g} \\max\\limits_{c} \\; \\left[ \\mathbb{E}(c(x)) \\; - \\; \\mathbb{E}(c(g(z))) \\right]$$\n",
    "\n",
    ", where:\n",
    "\n",
    "- $g$ is the generator\n",
    "- $c$ is the critic (aka the discriminator, but we won't it call it that because it's not a binary classifier, ie, now it doesn't classify values as real or fake, but rather assigns a score to them)\n",
    "- $x$ is the real values\n",
    "- $z$ is the noise vector\n",
    "\n",
    "So, the critic (earlier called discriminator) is trying to maximize the distance between what it thinks are real images and what it thinks are fake images. In other words, it is trying to push away these two distributions to be as far apart as possible. Meanwhile, the generator is trying to minimize this distance, because it wants the critic to think that its fake images are as close as possible to the real images.\n",
    "\n",
    "> The last layer of the critic's neural network.\n",
    "\n",
    "When we use the BCE Loss, the output of the discriminator needs to be a prediction between 0 and 1, ie, whether the value is real or fake. And so the discriminator's neural network for GANs, trained with BCE Loss, needs to have a sigmoid activation function in the output layer to then squash the values between 0 and 1. On the contrary, W-Loss doesn't have that requirement at all, so you can actually have a linear layer at the end of the discriminator's neural network (now called critic), and that could produce any real value output. And you can interpret that output as how real an image is considered by the critic.\n",
    "\n",
    "> Advantages of critic over discriminator.\n",
    "\n",
    "What's common between the discriminator and critic is that they both want to maximize the difference between the expected values of the predictions for real and fake.\n",
    "\n",
    "Both critic (W-Loss) and discriminator (BCE loss) measure the distance between the fake and the real distributions. However, the discriminator is bounded between 0 and 1 (ie, it outputs that the image it is fed is either fake or real, and not how much fake or how much real), whereas the critic is no longer bounded ,and just trying to separate the two distributions as much as possible. And as a result, because critic is not bounded, it is allowed to improve without degrading its feedback back to the generator. This is how the critic helps to mitigate the vanishing gradient problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Condition on Wasserstein Critic**\n",
    "\n",
    "> The 1-Lipschitz Continuous condition.\n",
    "\n",
    "Up until now, we have seen that WGAN can solve problems like mode collapse and vanishing gradient problem faced by the simple GAN and the DCGAN models. However, in order for it to work well, there is one special condition that needs to be met by the Critic model. This condition is called 1-Lipschitz Continuous (or 1-L Continuous, for short). For a function like the Critic model to be 1-Lipschitz Continuous, the norm of its gradient needs to be at most one for every point. This means that the slope can't be greater than one at any point, ie, its gradient can't be greater than one. The big picture is that the gradients of the Critic model should not change very rapidly. \n",
    "\n",
    "> How to mathematically check if a function is 1-Lipschitz Continuous.\n",
    "\n",
    "It's a bit difficult to describe in words (tbh, I'm just too lazy to plot the graphs and describe the whole thing to you ;)) how to mathematically check if a function is 1-Lipschitz Continuous as it involves graphing the function in consideration, then drawing 2 lines, one with slope 1 and and the other with slope -1, and checking if the graph of the function lies within those 2 lines at every point. If it does, then the function is 1-Lipschitz Continuous, otherwise it's not. So, for this, I highly recommend watching the video titled \"Condition on Wasserstein Critic\" in Course 1 Week 3 of the [GANs specialization on Coursera](https://www.coursera.org/specializations/generative-adversarial-networks-gans).\n",
    "\n",
    "> Benefits of the 1-Lipschitz Continuous condition.\n",
    "\n",
    "This condition on the Critic model is important for W-Loss because it assures that the W-Loss function is not only continuous and differentiable, but also that it doesn't grow too much and maintain some stability during training. This is required for training both the Critic and Generator models and it also increases stability because the variation as the GAN learns will be bounded. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1-Lipschitz Continuity Enforcement**\n",
    "\n",
    "something"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alright enough theory, let's write some code now!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SomeDataClass:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        pass\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Architectures and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim=10, img_channel=1, hidden_dim=64):\n",
    "        \"\"\"\n",
    "        The Generator class.\n",
    "\n",
    "        Parameters:\n",
    "            - z_dim: the dimension of the noise vector, a scalar\n",
    "            - img_channel: the number of channels of the output image, a scalar\n",
    "                (MNIST is grayscale, so default value is img_channel=1)\n",
    "            - hidden_dim: the inner dimension, a scalar\n",
    "        \"\"\"\n",
    "        super(Generator, self).__init__()\n",
    "        self.z_dim = z_dim\n",
    "        self.gen = nn.Sequential(\n",
    "            self.gen_block(z_dim, hidden_dim*4),\n",
    "            self.gen_block(hidden_dim*4, hidden_dim*2, kernel_size=4, stride=1),\n",
    "            self.gen_block(hidden_dim*2, hidden_dim),\n",
    "            self.gen_block(hidden_dim, img_channel, kernel_size=4, final_layer=True)\n",
    "        )\n",
    "\n",
    "    def gen_block(self, in_channel, out_channel, kernel_size=3, stride=2, \n",
    "                  final_layer=False):\n",
    "        \"\"\"\n",
    "        Returns the layers of a generator block.\n",
    "\n",
    "        Parameters:\n",
    "        - in_channel: the number of channels in the input, a scalar\n",
    "        - out_channel: the number of channels in the output, a scalar\n",
    "        - kernel_size: the size of the kernel, a scalar\n",
    "        - stride: the stride of the kernel, a scalar\n",
    "        - final_layer: a boolean, True if this is the final layer and False otherwise\n",
    "        \"\"\"\n",
    "        if not final_layer:\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(in_channel, out_channel, \n",
    "                                   kernel_size=kernel_size, stride=stride),\n",
    "                nn.BatchNorm2d(out_channel),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "        else:\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(in_channel, out_channel, \n",
    "                                   kernel_size=kernel_size, stride=stride),\n",
    "                nn.Tanh()\n",
    "            )\n",
    "    \n",
    "    def forward(self, noise):\n",
    "        \"\"\"\n",
    "        Given a noise tensor, returns the generated image.\n",
    "        \"\"\"\n",
    "        x = noise.view(len(noise), self.z_dim, 1, 1)\n",
    "        return self.gen(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that there is no change in the architecture of the Generator of WGAN model as compared to that of the DCGAN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "    def __init__(self, img_channel=1, hidden_dim=64):\n",
    "        \"\"\"\n",
    "        The Critic class.\n",
    "\n",
    "        Parameters:\n",
    "        - img_channel: the number of channels of the input image, a scalar\n",
    "            (MNIST is grayscale, so default value is img_channel=1)\n",
    "        - hidden_dim: the inner dimension, a scalar\n",
    "        \"\"\"\n",
    "        super(Critic, self).__init__()\n",
    "        self.critic = nn.Sequential(\n",
    "            self.critic_block(img_channel, hidden_dim),\n",
    "            self.critic_block(hidden_dim, hidden_dim*2),\n",
    "            self.critic_block(hidden_dim*2, 1, final_layer=True)\n",
    "        )\n",
    "\n",
    "    def critic_block(self, in_channel, out_channel, kernel_size=4, stride=2,\n",
    "                   final_layer=False):\n",
    "          \"\"\"\n",
    "          Returns the layers of a critic block.\n",
    "    \n",
    "          Parameters:\n",
    "          - in_channel: the number of channels in the input, a scalar\n",
    "          - out_channel: the number of channels in the output, a scalar\n",
    "          - kernel_size: the size of the kernel, a scalar\n",
    "          - stride: the stride of the kernel, a scalar\n",
    "          - final_layer: a boolean, True if this is the final layer and False otherwise\n",
    "          \"\"\"\n",
    "          if not final_layer:\n",
    "                return nn.Sequential(\n",
    "                    nn.Conv2d(in_channel, out_channel, kernel_size=kernel_size, \n",
    "                            stride=stride),\n",
    "                    nn.BatchNorm2d(out_channel),\n",
    "                    nn.LeakyReLU(0.2, inplace=True)\n",
    "                )\n",
    "          else:\n",
    "                return nn.Sequential(\n",
    "                    nn.Conv2d(in_channel, out_channel, kernel_size=kernel_size, \n",
    "                            stride=stride)\n",
    "                )\n",
    "\n",
    "    def forward(self, image):\n",
    "        \"\"\"\n",
    "        Given an image tensor, returns a 1-dimension tensor \n",
    "        representing fake/real.\n",
    "        Parameters:\n",
    "            image: a flattened image tensor\n",
    "        \"\"\"\n",
    "        critic_pred = self.critic(image)\n",
    "        return critic_pred.view(len(critic_pred), -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "lr = 2e-4           \n",
    "z_dim = 64          # latent noise dimension\n",
    "img_dim = 1         # 1 means grayscale image\n",
    "batch_size = 128\n",
    "num_epochs = 50\n",
    "display_step = 500   # after how many steps to display loss\n",
    "\n",
    "# These parameters control the Adam optimizer's momentum:\n",
    "# https://distill.pub/2017/momentum/\n",
    "beta_1 = 0.5 \n",
    "beta_2 = 0.999\n",
    "\n",
    "c_lambda = 10         # weight of the gradient penalty\n",
    "crit_repeats = 5      # number of times to update the critic per generator update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the architectures of the Critic (of WGAN model) and the Discriminator (of the DCGAN model) are almost the same. The only difference is that the Critic has a linear output layer, whereas the Discriminator has a sigmoid output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training loop and loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gen_loss():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crit_loss():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_step():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_fn():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the models' weights and Inferring on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
