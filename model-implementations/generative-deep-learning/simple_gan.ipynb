{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative Adversarial Network (GAN)\n",
    "\n",
    "Paper: [Generative Adversarial Nets](https://arxiv.org/pdf/1406.2661)\n",
    "\n",
    "Helpful Resources:\n",
    "- [Aladdin Persson's playlist on GANs](https://youtube.com/playlist?list=PLhhyoLH6IjfwIp8bZnzX8QR30TRcHO8Va&si=8ooImkbbXhCUC1xB)\n",
    "- [GANs specialization on coursera](https://www.coursera.org/specializations/generative-adversarial-networks-gans)\n",
    "- [Stanford's Deep Generative Models playlist](https://youtube.com/playlist?list=PLoROMvodv4rPOWA-omMM6STXaWW4FvJT8&si=N_TpTe1bPIhte-t8)\n",
    "- [AssemblyAI's GAN tutorial](https://youtu.be/_pIMdDWK5sc?si=Mtx2oWh1ZO9tqWYg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports done!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"Imports done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_dim):\n",
    "        \"\"\"\n",
    "        - param img_dim: dimension of image (eg: 28x28x1 = 784 for \n",
    "            grayscale MNIST images)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            nn.Linear(img_dim, 128),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()   # output between 0 and 1\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.disc(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim, img_dim):\n",
    "        \"\"\"\n",
    "        - param z_dim: dimension of latent noise vector\n",
    "        - param img_dim: dimension of image (eg: 28x28x1 = 784 for \n",
    "            grayscale MNIST images)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            nn.Linear(z_dim, 256),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Linear(256, img_dim),\n",
    "            nn.Tanh()   # output between -1 and 1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gen(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "lr = 3e-4   # Karpathy constant\n",
    "z_dim = 64\n",
    "img_dim = 28*28*1   # 1 means grayscale image\n",
    "batch_size = 32\n",
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# we can use the actual mean and std of the MNIST dataset, ie,\n",
    "# transforms.Normalize((0.1307,), (0.3081,))\n",
    "\n",
    "train_dataset = MNIST(root=\"dataset/\", transform=transformations, download=True, train=True)\n",
    "test_dataset = MNIST(root=\"dataset/\", transform=transformations, download=True, train=False)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn():\n",
    "    for item in train_loader:\n",
    "        print(len(item))\n",
    "        print(item[0].shape, item[1].shape)\n",
    "        break\n",
    "\n",
    "fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc = Discriminator(img_dim).to(device)\n",
    "gen = Generator(z_dim, img_dim).to(device)\n",
    "\n",
    "# fixed_noise is the latent noise vector\n",
    "# torch.randn generates random numbers from a normal distribution\n",
    "fixed_noise = torch.randn((batch_size, z_dim)).to(device)\n",
    "\n",
    "# separate optimizers for generator and discriminator\n",
    "optim_disc = optim.Adam(disc.parameters(), lr=lr)\n",
    "optim_gen = optim.Adam(gen.parameters(), lr=lr)\n",
    "\n",
    "criterion = nn.BCELoss()  # binary cross entropy loss\n",
    "\n",
    "# for tensorboard\n",
    "writer_fake = SummaryWriter(f\"logs/fake\")\n",
    "writer_real = SummaryWriter(f\"logs/real\")\n",
    "step = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall: \n",
    "\n",
    "The training of the discriminator was to ***maximize*** the following:\n",
    "\n",
    "$$\\text{log}(D(\\text{real\\_img})) \\; + \\; \\text{log}(1 - D(G(z)))$$\n",
    "\n",
    ", where:\n",
    "\n",
    "- $D$ is the discriminator\n",
    "- $G$ is the generator\n",
    "- $z$ is the latent noise vector\n",
    "- $\\text{real\\_img}$ is the real image\n",
    "- $G(z)$ is the image generated by the generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A note about using BCELoss. \n",
    "\n",
    "The formula for BCELoss in PyTorch is:\n",
    "\n",
    "$$\\text{BCELoss} = -w_n [y_i \\cdot \\text{log}(x_i) + (1 - y_i) \\cdot \\text{log}(1 - x_i)]$$\n",
    "\n",
    "We will set $w_n = 1$ for now, so no need to worry about that. The formula for BCELoss becomes:\n",
    "\n",
    "$$\\text{BCELoss} = -[y_i \\cdot \\text{log}(x_i) + (1 - y_i) \\cdot \\text{log}(1 - x_i)]$$\n",
    "\n",
    "Notice, the negative sign at the beginning. We will minimize this BCE loss, which is the same as maximizing the discriminator's loss.\n",
    "\n",
    "Our discriminator's loss is:\n",
    "\n",
    "$$\\text{log}(D(\\text{real\\_img})) \\; + \\; \\text{log}(1 - D(G(z)))$$\n",
    "\n",
    "So, in the BCELoss formula, if we set $y_i = 1$ and $x_i = D(\\text{real\\_img})$, we get:\n",
    "\n",
    "$$-[\\text{log}(D(\\text{real\\_img}))]$$\n",
    "\n",
    "This was the first term in the discriminator's loss. For the second term, if we set $y_i = 0$ and $x_i = D(G(z))$, we get:\n",
    "\n",
    "$$-[\\text{log}(1 - D(G(z)))]$$\n",
    "\n",
    "Now, if we add these two terms, we get the discriminator's loss, ie,\n",
    "\n",
    "$$-[\\text{log}(D(\\text{real\\_img})) \\; + \\; \\text{log}(1 - D(G(z)))]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to re-use the fake images generated by the generator, ie, `fake_img = gen(noise)` or mathematically, $G(z)$, but when we call `lossD.backward()`, the gradients are cleared from memory to save space. This means that we will need to re-generate the fake images, which is computationally expensive. We have 2 options to solve this problem:\n",
    "1. We can detach the fake images from the computational graph by calling `disc_fake = disc(fake_img.detach()).view(-1)`.\n",
    "2. We can call `lossD.backward(retain_graph=True)` to save the gradients for the generator.\n",
    "\n",
    "Both the options are equivalent, and going ahead with either of them is fine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall: \n",
    "\n",
    "The training of the generator was to ***minimize*** the following:\n",
    "\n",
    "$$\\text{log}(1 - D(G(z)))$$\n",
    "\n",
    "However, this causes the vanishing gradient problem, which leads to slower training, and sometimes even no training. To solve this, we can use an equivalent form of the above, which is to **maximize** the following:\n",
    "\n",
    "$$\\text{log}(D(G(z)))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the BCELoss for the generator in a similar fashion as we did for the discriminator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(num_epochs)):\n",
    "    \n",
    "    # we iterate over the training dataloader\n",
    "    # we only need the images, and not the labels\n",
    "    for batch_idx, (real_img, _) in enumerate(train_loader):\n",
    "        \n",
    "        # flatten the image to a 1D tensor, but keep the batch size\n",
    "        real_img = real_img.view(-1, 784).to(device)\n",
    "        # the first dimension of the tensor is the batch size\n",
    "        batch_size = real_img.shape[0]\n",
    "\n",
    "        # Discriminator training: max(log(D(x)) + log(1 - D(G(z))))\n",
    "        noise = torch.randn(batch_size, z_dim).to(device)  # z\n",
    "        fake_img = gen(noise)  # G(z)\n",
    "        disc_real = disc(real_img).view(-1)   # D(x) --> .view(-1) flattens the tensor\n",
    "        lossD_real = criterion(disc_real, torch.ones_like(disc_real))  # log(D(x))\n",
    "        disc_fake = disc(fake_img.detach()).view(-1)  # D(G(z))\n",
    "        lossD_fake = criterion(disc_fake, torch.zeros_like(disc_fake))  # log(1 - D(G(z)))\n",
    "        lossD = (lossD_real + lossD_fake) / 2  # (log(D(x)) + log(1 - D(G(z)))) / 2\n",
    "        \n",
    "        disc.zero_grad()\n",
    "        lossD.backward()\n",
    "        optim_disc.step()\n",
    "\n",
    "        # Generator training: max(log(D(G(z))))\n",
    "        disc_fake2 = disc(fake_img).view(-1)  # D(G(z))\n",
    "        lossG = criterion(disc_fake2, torch.ones_like(disc_fake2))  # log(D(G(z)))\n",
    "        \n",
    "        gen.zero_grad()\n",
    "        lossG.backward()\n",
    "        optim_gen.step()\n",
    "\n",
    "        if batch_idx == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch}/{num_epochs}] Batch {batch_idx}/{len(loader)} \\\n",
    "                      Loss D: {lossD:.4f}, loss G: {lossG:.4f}\"\n",
    "            )\n",
    "\n",
    "            with torch.no_grad():\n",
    "                fake = gen(fixed_noise).reshape(-1, 1, 28, 28)\n",
    "                data = real.reshape(-1, 1, 28, 28)\n",
    "                img_grid_fake = torchvision.utils.make_grid(fake, normalize=True)\n",
    "                img_grid_real = torchvision.utils.make_grid(data, normalize=True)\n",
    "\n",
    "                writer_fake.add_image(\n",
    "                    \"Mnist Fake Images\", img_grid_fake, global_step=step\n",
    "                )\n",
    "                writer_real.add_image(\n",
    "                    \"Mnist Real Images\", img_grid_real, global_step=step\n",
    "                )\n",
    "                step += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
