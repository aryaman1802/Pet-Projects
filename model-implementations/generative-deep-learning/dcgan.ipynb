{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Convolutional Generative Adversarial Network (DCGAN)\n",
    "\n",
    "Paper: [Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks](https://arxiv.org/pdf/1511.06434v2)\n",
    "\n",
    "Helpful Resources:\n",
    "- [Aladdin Persson's playlist on GANs](https://youtube.com/playlist?list=PLhhyoLH6IjfwIp8bZnzX8QR30TRcHO8Va&si=8ooImkbbXhCUC1xB)\n",
    "- [GANs specialization on coursera](https://www.coursera.org/specializations/generative-adversarial-networks-gans)\n",
    "- [Stanford's Deep Generative Models playlist](https://youtube.com/playlist?list=PLoROMvodv4rPOWA-omMM6STXaWW4FvJT8&si=N_TpTe1bPIhte-t8)\n",
    "- [AssemblyAI's GAN tutorial](https://youtu.be/_pIMdDWK5sc?si=Mtx2oWh1ZO9tqWYg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports done!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "print(\"Imports done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(img_tensor, num_imgs=25, size=(1,28,28)):\n",
    "    \"\"\"\n",
    "    Given a tensor of images, number of images, and size per image, \n",
    "    this function plots and prints the images in a uniform grid.\n",
    "    \"\"\"\n",
    "    img_unflat = img_tensor.detach().cpu().view(-1, *size)\n",
    "    img_grid = make_grid(img_unflat[:num_imgs], nrow=5)\n",
    "    plt.imshow(img_grid.permute(1,2,0).squeeze())\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(results):\n",
    "    \"\"\"\n",
    "    results is dictionary with keys: \"gen_train_loss\", \"gen_test_loss\", \n",
    "        \"disc_train_loss\", \"disc_test_loss\", \"gen_train_acc\", \"gen_test_acc\", \n",
    "        \"disc_train_acc\", \"disc_test_acc\".\n",
    "    This function plots the train and test losses and accuracies.\n",
    "\n",
    "    However, for now, we'll only plot the train losses for the generator and discriminator.\n",
    "    \"\"\"\n",
    "    plt.plot(results[\"gen_train_loss\"], label=\"Generator train loss\")\n",
    "    plt.plot(results[\"disc_train_loss\"], label=\"Discriminator train loss\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quoting from the DCGAN paper:\n",
    "\n",
    "> Architecture guidelines for stable Deep Convolutional GANs:\n",
    "> - Replace any pooling layers with strided convolutions (discriminator) and fractional-strided convolutions (generator).\n",
    "> - Use batchnorm in both the generator and the discriminator.\n",
    "> - Remove fully connected hidden layers for deeper architectures.\n",
    "> - Use ReLU activation in generator for all layers except for the output, which uses Tanh.\n",
    "> - Use LeakyReLU activation in the discriminator for all layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim=10, img_channel=1, hidden_dim=64):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        - z_dim: the dimension of the noise vector, a scalar\n",
    "        - img_channel: the number of channels of the output image, a scalar\n",
    "            (MNIST is grayscale, so default value is img_channel=1)\n",
    "        - hidden_dim: the inner dimension, a scalar\n",
    "        \"\"\"\n",
    "        super(Generator, self).__init__()\n",
    "        self.z_dim = z_dim\n",
    "        self.gen = nn.Sequential(\n",
    "            self.gen_block(z_dim, hidden_dim*4),\n",
    "            self.gen_block(hidden_dim*4, hidden_dim*2, kernel_size=4, stride=1),\n",
    "            self.gen_block(hidden_dim*2, hidden_dim),\n",
    "            self.gen_block(hidden_dim, img_channel, kernel_size=4, final_layer=True)\n",
    "        )\n",
    "\n",
    "    def gen_block(self, in_channel, out_channel, kernel_size=3, stride=2, \n",
    "                  final_layer=False):\n",
    "        \"\"\"\n",
    "        Returns the layers of a generator block.\n",
    "\n",
    "        Parameters:\n",
    "        - in_channel: the number of channels in the input, a scalar\n",
    "        - out_channel: the number of channels in the output, a scalar\n",
    "        - kernel_size: the size of the kernel, a scalar\n",
    "        - stride: the stride of the kernel, a scalar\n",
    "        - final_layer: a boolean, True if this is the final layer and False otherwise\n",
    "        \"\"\"\n",
    "        if not final_layer:\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(in_channel, out_channel, \n",
    "                                   kernel_size=kernel_size, stride=stride),\n",
    "                nn.BatchNorm2d(out_channel),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "        else:\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(in_channel, out_channel, \n",
    "                                   kernel_size=kernel_size, stride=stride),\n",
    "                nn.Tanh()\n",
    "            )\n",
    "        \n",
    "    def forward(self, noise):\n",
    "        \"\"\"\n",
    "        Given a noise tensor, returns the generated image.\n",
    "        \"\"\"\n",
    "        x = noise.view(len(noise), self.z_dim, 1, 1)\n",
    "        return self.gen(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_channel=1, hidden_dim=16):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        - img_channel: the number of channels of the input image, a scalar\n",
    "            (MNIST is grayscale, so default value is img_channel=1)\n",
    "        - hidden_dim: the inner dimension, a scalar\n",
    "        \"\"\"\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            self.disc_block(img_channel, hidden_dim),\n",
    "            self.disc_block(hidden_dim, hidden_dim*2),\n",
    "            self.disc_block(hidden_dim*2, 1, final_layer=True)\n",
    "        )\n",
    "\n",
    "    def disc_block(self, in_channel, out_channel, kernel_size=4, stride=2,\n",
    "                   final_layer=False):\n",
    "          \"\"\"\n",
    "          Returns the layers of a discriminator block.\n",
    "    \n",
    "          Parameters:\n",
    "          - in_channel: the number of channels in the input, a scalar\n",
    "          - out_channel: the number of channels in the output, a scalar\n",
    "          - kernel_size: the size of the kernel, a scalar\n",
    "          - stride: the stride of the kernel, a scalar\n",
    "          - final_layer: a boolean, True if this is the final layer and False otherwise\n",
    "          \"\"\"\n",
    "          if not final_layer:\n",
    "                return nn.Sequential(\n",
    "                 nn.Conv2d(in_channel, out_channel, kernel_size=kernel_size, \n",
    "                           stride=stride),\n",
    "                 nn.BatchNorm2d(out_channel),\n",
    "                 nn.LeakyReLU(0.2)\n",
    "                )\n",
    "          else:\n",
    "                return nn.Sequential(\n",
    "                 nn.Conv2d(in_channel, out_channel, kernel_size=kernel_size, \n",
    "                           stride=stride),\n",
    "                nn.Sigmoid()\n",
    "                )\n",
    "\n",
    "    def forward(self, image):\n",
    "        \"\"\"\n",
    "        Given an image tensor, returns a 1-dimension tensor \n",
    "        representing fake/real.\n",
    "        Parameters:\n",
    "            image: a flattened image tensor\n",
    "        \"\"\"\n",
    "        disc_pred = self.disc(image)\n",
    "        return disc_pred.view(len(disc_pred), -1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up till now, we observed changes in the architectures of the generator and the discriminator.\n",
    "\n",
    "Let's now move onto the training loop and the loss functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
